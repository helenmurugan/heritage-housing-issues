{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0aStgWSO0E0E"
      },
      "source": [
        "# Data Visualisations Notebook"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1eLEkw5O0ECa"
      },
      "source": [
        "## Objectives\n",
        "\n",
        "* Answer business requirement 1 \n",
        "    * Second iteration of Data Visualisations\n",
        "    * Identify features that are most correlated to sale price (including data that was originally categorical, that was not included in the correlation study in version 1 of this notebook.)\n",
        "    * Generate data visualisations of correlated features against sale price.\n",
        "\n",
        "## Inputs\n",
        "\n",
        "* outputs/datasets/cleaned/house_prices_records_cleaned.csv\n",
        "\n",
        "## Outputs\n",
        "\n",
        "* Generate code that answers business requirement 1 by providing most relevant variables that correlate with sale price.\n",
        "* Provide data visualisations including:\n",
        "    * Heatmaps from correlation studies.\n",
        "    * Scatter plots for most important house attributes vs. SalePrice.\n",
        "    * Bar plots showing which attributes are most important in correlation studies.\n",
        "    * Pie charts showing the importance of house attributes for predicting SalePrice based on correlation studies.\n",
        "* Draw conclusions on which house attributes are most correlated with SalePrice.\n",
        "\n",
        "## Conclusions\n",
        "\n",
        "* The following features have a strong positive correlation with sale price: {'1stFlrSF', 'GarageArea', 'GrLivArea', 'OverallQual', 'TotalBsmtSF', 'YearBuilt', 'YearRemodAdd'}\n",
        "\n",
        "## Additional Comments\n",
        "This version uses a cleaned dataset as its input which allows data visualisations to be performed on all variables (except three that were dropped in data cleaning). This will give more valuable and comprehensive insights to answer the client's business requirement 1.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9uWZXH9LwoQg"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cqP-UeN-z3i2"
      },
      "source": [
        "# Change working directory"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aOGIGS-uz3i2"
      },
      "source": [
        "We need to change the working directory from its current folder to its parent folder\n",
        "* We access the current directory with os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wZfF_j-Bz3i4",
        "outputId": "66943449-1436-4c3d-85c7-b85f9f78349b"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MWW8E7lz3i7"
      },
      "source": [
        "We want to make the parent of the current directory the new current directory\n",
        "* os.path.dirname() gets the parent directory\n",
        "* os.chir() defines the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TwHsQRWjz3i9",
        "outputId": "86849db3-cd2f-4cc5-ebb8-2d0caafa1a2c"
      },
      "outputs": [],
      "source": [
        "os.chdir(os.path.dirname(current_dir))\n",
        "print(\"You set a new current directory\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M_xPk_Ijz3i-"
      },
      "source": [
        "Confirm the new current directory"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vz3S-_kjz3jA",
        "outputId": "00b79ae4-75d0-4a96-d193-ac9ef9847ea2"
      },
      "outputs": [],
      "source": [
        "current_dir = os.getcwd()\n",
        "current_dir"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-mavJ8DibrcQ"
      },
      "source": [
        "# Load Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = (pd.read_csv(\"outputs/datasets/cleaned/house_prices_records_cleaned.csv\"))\n",
        "df.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZY3l0-AxO93d"
      },
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uFQo3ycuO-v6"
      },
      "source": [
        "# Data Exploration"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate pandas report to gain insights on dataset, including data types, missing data and distribution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ydata_profiling import ProfileReport\n",
        "pandas_report = ProfileReport(df=df, minimal=True)\n",
        "pandas_report.to_notebook_iframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observations from pandas profile report\n",
        "* The dataset has 21 variables (columns) and 1460 observations (rows).\n",
        "* The dataset has only numeric variables.\n",
        "* The data for sales price has a positively skewed distribution, with the majority of observations for sales prices in the range $130k to $214k (interquartile range). There is limited sales price data in the range from $350k+. It will be difficult to build a model that can accurately predict sale prices above $350k and this may be a problem for the client if any of their four inherited houses fall in this range, this is a potential limitation of the model and would need to be discussed with the client."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Detailed Correlation Study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We use the `.corr()` method with `spearman` to determine the top 10 variables most strongly correlated to SalePrice.\n",
        "* The list is sliced at index 1 to exclude the first element because we don't want to include SalePrice v SalePrice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_spearman = df.corr(method='spearman')['SalePrice'].sort_values(key=abs, ascending=False)[1:].head(10) \n",
        "corr_spearman  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We use the `.corr()` method with `pearson` to determine the top 10 variables most strongly correlated to SalePrice.\n",
        "* The list is sliced at index 1 to exclude the first element because we don't want to include SalePrice v SalePrice."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_pearson = df.corr(method='pearson')['SalePrice'].sort_values(key=abs, ascending=False)[1:].head(10) \n",
        "corr_pearson"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Moderate to very strong correlations were noticed with both Spearman and Pearson methods.\n",
        "* We will consider only the variables that are strongly correlated with a value > 0.5 or < -0.5.\n",
        "* We concatenate the strong variables list from spearman and pearson correlations. 'set' ensures each variable appears only once in the new list."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pearson_variables_strong = corr_pearson[(corr_pearson > 0.5) | (corr_pearson < -0.5)].index.tolist()\n",
        "spearman_variables_strong = corr_spearman[(corr_spearman > 0.5) | (corr_spearman < -0.5)].index.tolist()\n",
        "\n",
        "variables_with_strong_correlation = set(pearson_variables_strong + spearman_variables_strong)\n",
        "variables_with_strong_correlation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "We now have seven of the most important variables for predicting house sale price, all of which are strongly correlated to SalePrice. These are listed in alphabetical order, not order of importance.\n",
        "* First floor area in square feet\n",
        "* Garage area in square feet\n",
        "* Above grade (ground) living area in square feet\n",
        "* Overall quality of materials and finishes\n",
        "* Total basement area in square feet\n",
        "* Original construction date\n",
        "* Year of remodelling (or build if it has not been remodelled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "vars_to_study = ['1stFlrSF',\n",
        "                'GarageArea',\n",
        "                'GrLivArea',\n",
        "                'OverallQual',\n",
        "                'TotalBsmtSF',\n",
        "                'YearBuilt',\n",
        "                'YearRemodAdd'] \n",
        "vars_to_study"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Detailed Correlation and PPS Analysis"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The following code taken from CI Churnometer project is designed to visualise the correlation and Predictive Power Score (PPS) matrices of the dataframe, in the following way:\n",
        "* heatmap_corr: generates a heatmap to visualise the correlation matrix of the df. It masks values below a certain threshold and annotates the heatmap with correlation coefficients.\n",
        "* heatmap_pps: generates a heatmap to visualise the PPS matrix of the df. It masks values below a certain threshold and annotates the heatmap with PPS scores.\n",
        "* CalculateCorrAndPPS: calculates the Pearson and Spearman correlation matrices, as well as the PPS matrix of the input df.\n",
        "* DisplayCorrAndPPS: displays the correlation matrices (Pearson and Spearman) and the PPS matrix using heatmaps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import ppscore as pps\n",
        "\n",
        "\n",
        "def heatmap_corr(df, threshold, figsize=(20, 12), font_annot=8):\n",
        "    if len(df.columns) > 1:\n",
        "        mask = np.zeros_like(df, dtype=np.bool)\n",
        "        mask[np.triu_indices_from(mask)] = True\n",
        "        mask[abs(df) < threshold] = True\n",
        "\n",
        "        fig, axes = plt.subplots(figsize=figsize)\n",
        "        sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
        "                    mask=mask, cmap='viridis', annot_kws={\"size\": font_annot}, ax=axes,\n",
        "                    linewidth=0.5\n",
        "                    )\n",
        "        axes.set_yticklabels(df.columns, rotation=0)\n",
        "        plt.ylim(len(df.columns), 0)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def heatmap_pps(df, threshold, figsize=(20, 12), font_annot=8):\n",
        "    if len(df.columns) > 1:\n",
        "        mask = np.zeros_like(df, dtype=np.bool)\n",
        "        mask[abs(df) < threshold] = True\n",
        "        fig, ax = plt.subplots(figsize=figsize)\n",
        "        ax = sns.heatmap(df, annot=True, xticklabels=True, yticklabels=True,\n",
        "                         mask=mask, cmap='rocket_r', annot_kws={\"size\": font_annot},\n",
        "                         linewidth=0.05, linecolor='grey')\n",
        "        plt.ylim(len(df.columns), 0)\n",
        "        plt.show()\n",
        "\n",
        "\n",
        "def CalculateCorrAndPPS(df):\n",
        "    df_corr_spearman = df.corr(method=\"spearman\")\n",
        "    df_corr_pearson = df.corr(method=\"pearson\")\n",
        "\n",
        "    pps_matrix_raw = pps.matrix(df)\n",
        "    pps_matrix = pps_matrix_raw.filter(['x', 'y', 'ppscore']).pivot(columns='x', index='y', values='ppscore')\n",
        "\n",
        "    pps_score_stats = pps_matrix_raw.query(\"ppscore < 1\").filter(['ppscore']).describe().T\n",
        "    print(\"PPS threshold - check PPS score IQR to decide threshold for heatmap \\n\")\n",
        "    print(pps_score_stats.round(3))\n",
        "\n",
        "    return df_corr_pearson, df_corr_spearman, pps_matrix\n",
        "\n",
        "\n",
        "def DisplayCorrAndPPS(df_corr_pearson, df_corr_spearman, pps_matrix, CorrThreshold, PPS_Threshold,\n",
        "                      figsize=(20, 12), font_annot=8):\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"* Analyse how the target variable for your ML models are correlated with other variables (features and target)\")\n",
        "    print(\"* Analyse multi-colinearity, that is, how the features are correlated among themselves\")\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"*** Heatmap: Spearman Correlation ***\")\n",
        "    print(\"It evaluates monotonic relationship \\n\")\n",
        "    heatmap_corr(df=df_corr_spearman, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"*** Heatmap: Pearson Correlation ***\")\n",
        "    print(\"It evaluates the linear relationship between two continuous variables \\n\")\n",
        "    heatmap_corr(df=df_corr_pearson, threshold=CorrThreshold, figsize=figsize, font_annot=font_annot)\n",
        "\n",
        "    print(\"\\n\")\n",
        "    print(\"*** Heatmap: Power Predictive Score (PPS) ***\")\n",
        "    print(f\"PPS detects linear or non-linear relationships between two columns.\\n\"\n",
        "          f\"The score ranges from 0 (no predictive power) to 1 (perfect predictive power) \\n\")\n",
        "    heatmap_pps(df=pps_matrix, threshold=PPS_Threshold, figsize=figsize, font_annot=font_annot)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Calculate Correlations and Power Predictive Score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_corr_pearson, df_corr_spearman, pps_matrix = CalculateCorrAndPPS(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* From the PPS interquartile range we can see the majority of values are between 0 and 0.028, which indicates there is a concentration of features with moderate predictive power.\n",
        "* A maximum PPS score of 0.579 suggests that there is at least one feature in the dataset that has a moderate association with another feature. Note this figure is lower than the original ppscore (in 02_Data_Cleaning_v2) because the feature 'GarageYrBlt' has been dropped and this was strongly corrlated to 'YearBuilt'.\n",
        "* A threshold of 0.2 was chosen to display features with low to moderate correlation or predictive power."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate heatmaps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "DisplayCorrAndPPS(df_corr_pearson = df_corr_pearson,\n",
        "                  df_corr_spearman = df_corr_spearman, \n",
        "                  pps_matrix = pps_matrix,\n",
        "                  CorrThreshold = 0.4, PPS_Threshold =0.2,\n",
        "                  figsize=(12,10), font_annot=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Observations from heatmap analyses:\n",
        "* Sales price has moderate to strong monotonic relationship (Spearman correlation) with 11 house attributes.\n",
        "* Sales price has moderate to strong linear relationship (Pearson correlation) with 8 house attributes.\n",
        "* OverallQual and GrLivArea have the strongest predictive power for the target variable.\n",
        "* Moderate multicollinearity correlations exist between several features, as expected.\n",
        "* We accept the detailed correlation study as being appropriate to generate data visualisations for the client with cleaned data. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# EDA on selected variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Create a new dataframe with the only selected variables and SalePrice for exploratory data analysis (EDA)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_eda = df.filter(vars_to_study + ['SalePrice']) \n",
        "df_eda.head(3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Variables Distribution by Sale Price"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* We plot the variables of interest against the SalePrice\n",
        "* We use a linear regression model to add a line of best fit to the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set_style('whitegrid')\n",
        "\n",
        "\n",
        "def plot_numerical(df_eda, col):\n",
        "    \"\"\"scatterplots of variables vs SalePrice \"\"\"\n",
        "    target_var = 'SalePrice'\n",
        "    for col in vars_to_study:\n",
        "        fig, axes = plt.subplots(figsize=(8, 5))\n",
        "        axes = sns.scatterplot(data=df_eda, x=col, y=target_var)\n",
        "        plt.title(f\"{col}\", fontsize=20, y=1.05)\n",
        "        plt.show()\n",
        "        print(\"\\n\\n\")\n",
        "plot_numerical(df_eda, vars_to_study)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate bar plots based on most important features from correlation study"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def display_spearman_corr_bar(df):\n",
        "    \"\"\" Calcuate and display Spearman Correlation \"\"\"\n",
        "    corr_spearman = df.corr(method='spearman')['SalePrice'].sort_values(\n",
        "        key=abs, ascending=False)[1:]\n",
        "    fig, axes = plt.subplots(figsize=(6, 3))\n",
        "    axes = plt.bar(x=corr_spearman[:5].index, height=corr_spearman[:5])\n",
        "    plt.title(\n",
        "        \"Spearman Correlation of Attributes with Sale Price\",\n",
        "        fontsize=15, y=1.05\n",
        "        )\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.ylabel(\"Spearman Coefficient\")\n",
        "    plt.show\n",
        "\n",
        "display_spearman_corr_bar(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def display_pearson_corr_bar(df):\n",
        "    \"\"\" Calcuate and display Pearson Correlation \"\"\"\n",
        "    corr_pearson = df.corr(method='pearson')['SalePrice'].sort_values(\n",
        "        key=abs, ascending=False)[1:]\n",
        "    fig, axes = plt.subplots(figsize=(6, 3))\n",
        "    axes = plt.bar(x=corr_pearson[:5].index, height=corr_pearson[:5])\n",
        "    plt.title(\n",
        "        \"Pearson Correlation of Attributes with Sale Price\",\n",
        "        fontsize=15, y=1.05\n",
        "        )\n",
        "    plt.xticks(rotation=90)\n",
        "    plt.ylabel(\"Pearson Coefficient\")\n",
        "    plt.show\n",
        "\n",
        "display_pearson_corr_bar(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Generate pie charts showing relative importance of house attributes for predicting SalePrice"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate dataframe from Spearman coefficients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_spearman_for_pie = df.corr(method='spearman')['SalePrice'].sort_values(key=abs, ascending=False)[1:]\n",
        "corr_spearman_for_pie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Reset index to make 'Feature' a column\n",
        "spearman_data = corr_spearman_for_pie.reset_index() \n",
        "\n",
        "# Rename columns\n",
        "spearman_data.columns = ['Feature', 'Correlation']\n",
        "\n",
        "# Convert to DataFrame\n",
        "df_corr_spearman = pd.DataFrame(spearman_data) \n",
        "\n",
        "print(df_corr_spearman)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate pie chart from Spearman coefficients dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Take the absolute value of the correlation values\n",
        "df_corr_spearman['Correlation'] = df_corr_spearman['Correlation'].abs()\n",
        "\n",
        "# Normalize the correlation values\n",
        "df_corr_spearman['Normalized_Correlation'] = df_corr_spearman['Correlation'] / df_corr_spearman['Correlation'].sum()\n",
        "\n",
        "# Plot a pie chart\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.pie(df_corr_spearman['Normalized_Correlation'], labels=df_corr_spearman['Feature'], autopct='%1.1f%%')\n",
        "plt.title('Importance of House Attributes for Predicting Sale Price based on Spearman Correlations')\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate dataframe from Pearson coefficients"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "corr_pearson_for_pie = df.corr(method='pearson')['SalePrice'].sort_values(key=abs, ascending=False)[1:]\n",
        "corr_pearson_for_pie"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "pearson_data = corr_pearson_for_pie.reset_index() \n",
        "\n",
        "pearson_data.columns = ['Feature', 'Correlation']\n",
        "\n",
        "df_corr_pearson = pd.DataFrame(pearson_data) \n",
        "\n",
        "print(df_corr_pearson)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Generate pie chart from Pearson coefficients dataframe"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df_corr_pearson['Correlation'] = df_corr_pearson['Correlation'].abs()\n",
        "\n",
        "\n",
        "df_corr_pearson['Normalized_Correlation'] = df_corr_pearson['Correlation'] / df_corr_pearson['Correlation'].sum()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(8, 8))\n",
        "plt.pie(df_corr_pearson['Normalized_Correlation'], labels=df_corr_pearson['Feature'], autopct='%1.1f%%')\n",
        "plt.title('Importance of House Attributes for Predicting Sale Price based on Pearson Correlations')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Conclusions"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "* Correlation heat maps have been generated with cleaned data. \n",
        "* Scatterplots have been made to allow the client to visualise how the most important house attributes correlate with sales price.\n",
        "* Bar plots have been generated to show most correlated features from correlation studies.\n",
        "* Pie charts have been generated to show the client which attributes contribute most strongly to sale price.\n",
        "\n",
        "* The following variables are most important and have a moderate or strong positive correlation with sale price.\n",
        "    * First floor area in square feet\n",
        "    * Garage area in square feet\n",
        "    * Above grade (ground) living area in square feet\n",
        "    * Overall quality of materials and finishes\n",
        "    * Total basement area in square feet\n",
        "    * Original construction date\n",
        "    * Year of remodelling (or build if it has not been remodelled)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Next Steps\n",
        "* Feature engineering - identify transformations to apply to specific variables, in preparation for ML modelling."
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Data Practitioner Jupyter Notebook.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "interpreter": {
      "hash": "8b8334dab9339717f727a1deaf837b322d7a41c20d15cc86be99a8e69ceec8ce"
    },
    "kernelspec": {
      "display_name": "Python 3.8.12 64-bit ('3.8.12': pyenv)",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.18"
    },
    "orig_nbformat": 2
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
